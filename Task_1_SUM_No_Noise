import numpy as np
import pandas as pd
from sklearn import neighbors
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Ridge
from sklearn.metrics import make_scorer, precision_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

sizes = [100, 500, 1000, 5000,10000, 50000, 100000, 500000]

filename = "The SUM Dataset Without Noise.csv"
sum_no_noise = pd.read_csv(filename, delimiter=";").drop(["Instance"], axis = 1)

sum_no_noise.loc[sum_no_noise["Target Class"] == "Very Large Number", "Target Class"] = 5
sum_no_noise.loc[sum_no_noise["Target Class"] == "Large Number", "Target Class"] = 4
sum_no_noise.loc[sum_no_noise["Target Class"] == "Medium Number", "Target Class"] = 3
sum_no_noise.loc[sum_no_noise["Target Class"] == "Small Number", "Target Class"] = 2
sum_no_noise.loc[sum_no_noise["Target Class"] == "Very Small Number", "Target Class"] = 1


# Normalise results list
def normalise_results(result_list):
    for item in range(len(result_list)):
        norm = np.linalg.norm(result_list)
        n = result_list[item] / norm
        result_list[item] = n
    return result_list


# Iterate through the different chunk sizes and apply each algorithm and metric
for size_index in range(len(sizes)):
    X = np.array(sum_no_noise[:sizes[size_index]])
    X = X[:,:-1]

    Y = np.array(sum_no_noise[:sizes[size_index]])
    Y = Y[:,-2]

    X = X.astype('int')
    Y = Y.astype('int')

    kf = KFold(n_splits=10, random_state=0)

    # Linear Regression
    lin_reg = LinearRegression()
    # - Mean Absolute Error
    lin_abs_error = cross_val_score(lin_reg, X, Y, cv=kf, scoring='neg_mean_absolute_error')
    lin_abs_error_norm = normalise_results(lin_abs_error)                                       # normalise results list
    mean_lin_abs_error = -1 * lin_abs_error_norm.mean()                                         # Multiply by -1 and find mean
    print(sizes[size_index], "lin mean absolute error: ", mean_lin_abs_error)

    # - Mean Squared Error
    lin_sq_error = cross_val_score(lin_reg, X, Y, cv=kf, scoring='neg_mean_squared_error')
    lin_sq_error_norm = normalise_results(lin_sq_error)                                         # normalise results list
    mean_lin_sq_error = -1 * lin_sq_error_norm.mean()                                           # Multiply by -1 and find mean
    print(sizes[size_index], "lin mean squared error: ", np.sqrt(mean_lin_sq_error))

    # Ridge Regression
    ridge_reg = Ridge()
    # - Mean Absolute Error
    ridge_abs_error = cross_val_score(ridge_reg, X, Y, cv=kf, scoring='neg_mean_absolute_error')
    ridge_abs_error_norm = normalise_results(ridge_abs_error)                                    # normalise results list
    mean_ridge_abs_error = -1 * ridge_abs_error_norm.mean()                                      # Multiply by -1 and find mean
    print(sizes[size_index], "ridge mean absolute error: ", mean_ridge_abs_error)

    # - Mean Squared Error
    ridge_sq_error = cross_val_score(ridge_reg, X, Y, cv=kf, scoring='neg_mean_squared_error')
    ridge_sq_error_norm = normalise_results(ridge_sq_error)                                     # normalise results list
    mean_ridge_sq_error = -1 * ridge_sq_error_norm.mean()                                       # Multiply by -1 and find mean
    print(sizes[size_index], "ridge mean squared error: ", np.sqrt(mean_ridge_sq_error))
    # Reset y value for Logistic Regression and Classification
    Y = np.array(sum_no_noise[:sizes[size_index]])
    Y = Y[:, -1]
    Y = Y.astype('int')

    # Logistic Regression
    log_reg = LogisticRegression()
    # - Accuracy
    accuracy = cross_val_score(log_reg, X, Y, cv=kf, scoring='accuracy')
    mean_accuracy = accuracy.mean()
    print(sizes[size_index], "accuracy: ", mean_accuracy)
    # - Average Precision
    score = make_scorer(precision_score, average="weighted")
    avg_precision = cross_val_score(log_reg, X, Y, cv=kf, scoring=score)
    mean_avg_precision = avg_precision.mean()
    print(sizes[size_index], "average precision: ", mean_avg_precision)

    # Other Classification - K-nearest Neighbours
    knn = neighbors.KNeighborsClassifier()
    # - Accuracy
    k_nn = cross_val_score(knn, X, Y, cv=kf, scoring='accuracy')
    mean_knn = k_nn.mean()
    print(sizes[size_index], "knn accuracy: ", mean_knn)
    # - Average Precision
    knn_avg_precision = cross_val_score(knn, X, Y, cv=kf, scoring=score)
    mean_knn_avg_precision = avg_precision.mean()
    print(sizes[size_index], "knn average precision: ", mean_knn_avg_precision)

    print("\n")
